{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤一：获取中证800分类数据（市值特点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin: DataApi login 18222272839@tcp://data.tushare.org:8910\n",
      "    login success \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jaqs_fxdayu.util import dp\n",
    "from jaqs.data.dataapi import DataApi\n",
    "from jaqs_fxdayu.data import RemoteDataService\n",
    "\n",
    "data_config = {\n",
    "    \"remote.data.address\": \"tcp://data.tushare.org:8910\",\n",
    "    \"remote.data.username\": \"18222272839\",\n",
    "    \"remote.data.password\": \"eyJhbGciOiJIUzI1NiJ9.eyJjcmVhdGVfdGltZSI6IjE1MjIxMzM5NzY0MzUiLCJpc3MiOiJhdXRoMCIsImlkIjoiMTgyMjIyNzI4MzkifQ.cPLnbs3mFP9uIeZ7o1wDrxwaDAsMAGZJ9l-hJZVCv5k\"\n",
    "}\n",
    "ds = api = RemoteDataService()\n",
    "ds.init_from_config(data_config)\n",
    "\n",
    "start = 20130101\n",
    "end = 20180101\n",
    "stock_symbol = list(set(dp.index_cons(ds, \"000906.SH\", start, end).symbol.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤二：读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_list = ['volume', 'pb', 'roe']\n",
    "check_factor = ','.join(factor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr. Sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\dayu\\lib\\importlib\\__init__.py:126: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "C:\\Users\\Mr. Sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\dayu\\lib\\site-packages\\matplotlib\\__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize config success.\n",
      "Query data...\n",
      "Query data - query...\n",
      "NOTE: price adjust method is [post adjust]\n",
      "当前请求daily...\n",
      "{'adjust_mode': None, 'fields': 'open_adj,open,trade_date,vwap_adj,trade_status,low_adj,low,close_adj,close,symbol,high_adj,volume,vwap,high'}\n",
      "下载进度398/1219.\n",
      "下载进度796/1219.\n",
      "下载进度1194/1219.\n",
      "当前请求daily...\n",
      "{'adjust_mode': 'post', 'fields': 'close,vwap,high,low,open,symbol,trade_date'}\n",
      "下载进度398/1219.\n",
      "下载进度796/1219.\n",
      "下载进度1194/1219.\n",
      "WARNING: some data is unavailable: \n",
      "    At fields 000024.SZ, 000522.SZ, 000527.SZ, 000562.SZ, 000748.SZ, 600005.SH, 600832.SH, 601268.SH, 601299.SH\n",
      "Query data - daily fields prepared.\n",
      "WARNING: some data is unavailable: \n",
      "    At fields 000024.SZ, 000522.SZ, 000527.SZ, 000562.SZ, 000748.SZ, 600005.SH, 600832.SH, 601268.SH, 601299.SH\n",
      "Query data - quarterly fields prepared.\n",
      "Query instrument info...\n",
      "Query adj_factor...\n",
      "Data has been successfully prepared.\n"
     ]
    }
   ],
   "source": [
    "import jaqs_fxdayu\n",
    "jaqs_fxdayu.patch_all()\n",
    "from jaqs_fxdayu.data import DataView\n",
    "from jaqs.data import RemoteDataService\n",
    "from jaqs_fxdayu.data.dataservice import LocalDataService\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataview_folder = 'E:/data/data'\n",
    "dv = DataView()\n",
    "ds = LocalDataService(fp=dataview_folder)\n",
    "\n",
    "\n",
    "factor_list = ['volume']\n",
    "check_factor = ','.join(factor_list)\n",
    "\n",
    "dv_props = {'start_date': start, 'end_date': end, 'symbol':','.join(stock_symbol),\n",
    "         'fields': check_factor,\n",
    "         'freq': 1,\n",
    "         \"prepare_fields\": True}\n",
    "\n",
    "dv.init_from_config(dv_props, data_api=ds)\n",
    "dv.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤三：获取分类数据\n",
    "可获取的分类：[sw1, sw2, sw3, zz1, zz2]\n",
    "\n",
    "sw1 = {'480000': '银行', '430000': '房地产', '460000': '休闲服务', '640000': '机械设备', '240000': '有色金属', '510000': '综合', '410000': '公用事业', '450000': '商业贸易', '730000': '通信', '330000': '家用电器', '720000': '传媒', '630000': '电气设备', '270000': '电子', '490000': '非银金融', '370000': '医药生物', '710000': '计算机', '280000': '汽车', '340000': '食品饮料', '220000': '化工', '210000': '采掘', '230000': '钢铁', '650000': '国防军工', '110000': '农林牧渔', '420000': '交通运输', '620000': '建筑装饰', '350000': '纺织服装', '610000': '建筑材料', '360000': '轻工制造'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv.add_field('sw1')\n",
    "sw1 = dv.get_ts('sw1')\n",
    "dict_classify = {'480000': '银行', '430000': '房地产', '460000': '休闲服务', '640000': '机械设备', '240000': '有色金属', '510000': '综合', '410000': '公用事业', '450000': '商业贸易', '730000': '通信', '330000': '家用电器', '720000': '传媒', '630000': '电气设备', '270000': '电子', '490000': '非银金融', '370000': '医药生物', '710000': '计算机', '280000': '汽车', '340000': '食品饮料', '220000': '化工', '210000': '采掘', '230000': '钢铁', '650000': '国防军工', '110000': '农林牧渔', '420000': '交通运输', '620000': '建筑装饰', '350000': '纺织服装', '610000': '建筑材料', '360000': '轻工制造'}\n",
    "sw1_name = sw1.replace(dict_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤四： 输入已经写好的八个因子（数据或算法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['TSEPToTotalCapital' 'alpha107' 'TRIX5' 'OperatingRevenueGrowRate' 'LossVariance60' 'BIAS60' 'alpha110' 'DIZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable [sh000300] is not recognized (it may be wrong),try to fetch from the server...\n",
      "Field name [sh000300] not valid, ignore.\n"
     ]
    }
   ],
   "source": [
    "dv.add_formula('hs300','sh000300',is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable [tot_shrhldr_eqy_incl_min_int] is not recognized (it may be wrong),try to fetch from the server...\n",
      "Query data - query...\n",
      "WARNING: some data is unavailable: \n",
      "    At fields 000024.SZ, 000522.SZ, 000527.SZ, 000562.SZ, 000748.SZ, 600005.SH, 600832.SH, 601268.SH, 601299.SH\n",
      "Query data - quarterly fields prepared.\n",
      "Variable [tot_assets] is not recognized (it may be wrong),try to fetch from the server...\n",
      "Query data - query...\n",
      "WARNING: some data is unavailable: \n",
      "    At fields 000024.SZ, 000522.SZ, 000527.SZ, 000562.SZ, 000748.SZ, 600005.SH, 600832.SH, 601268.SH, 601299.SH\n",
      "Query data - quarterly fields prepared.\n"
     ]
    }
   ],
   "source": [
    "TSEPToTotalCapital = TSEPToTotalCapital = dv.add_formula('TSEPToTotalCapital','tot_shrhldr_eqy_incl_min_int/tot_assets',is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha107 = dv.add_formula('alpha107',\n",
    "                          '(((-1 * Rank((open - Delay(high, 1)))) * Rank((open - Delay(close, 1)))) * Rank((open - Delay(low, 1))))',\n",
    "                          is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA=dv.get_ts('close').ewm(span=5, adjust=False).mean()\n",
    "EMA2=EMA.ewm(span=5, adjust=False).mean()\n",
    "EMA3=EMA2.ewm(span=5, adjust=False).mean()\n",
    "dv.append_df(EMA3,'EMA3')\n",
    "TRIX5 = dv.add_formula('TRIX5_J','EMA3/Delay(EMA3,1)-1',is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable [oper_profit] is not recognized (it may be wrong),try to fetch from the server...\n",
      "Query data - query...\n",
      "WARNING: some data is unavailable: \n",
      "    At fields 000024.SZ, 000522.SZ, 000527.SZ, 000562.SZ, 000748.SZ, 600005.SH, 600832.SH, 601268.SH, 601299.SH\n",
      "Query data - quarterly fields prepared.\n"
     ]
    }
   ],
   "source": [
    "OperatingRevenueGrowRate = dv.add_formula('OperatingRevenueGrowRate_J','TTM(oper_profit)/Delay(TTM(oper_profit),250)-1',is_quarterly=False, add_data=True)\n",
    "# OperatingRevenueGrowRate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable [OperatingRevenueGrowRate] is not recognized (it may be wrong),try to fetch from the server...\n",
      "Query data - query...\n",
      "当前请求query...\n",
      "{'view': 'factor', 'fields': 'OperatingRevenueGrowRate'}\n",
      "下载进度398/1219.\n",
      "下载进度796/1219.\n",
      "下载进度1194/1219.\n",
      "WARNING: some data is unavailable: \n",
      "    At fields 000024.SZ, 000522.SZ, 000527.SZ, 000562.SZ, 000748.SZ, 600005.SH, 600832.SH, 601268.SH, 601299.SH\n",
      "Query data - daily fields prepared.\n"
     ]
    }
   ],
   "source": [
    "OperatingRevenueGrowRate = dv.add_formula('OperatingRevenueGrowRate_JJ','OperatingRevenueGrowRate',is_quarterly=False, add_data=True)\n",
    "# OperatingRevenueGrowRate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = 'close_adj/Delay(close_adj,1)-1'\n",
    "# count = 'Ts_Sum(If(r>0,0,1),60)'\n",
    "# E = 'Ts_Sum(If(r>0,0,r*r-r),60)/count'\n",
    "dv.add_formula('daily_return_no_reinv',\n",
    "               'close_adj/Delay(close_adj,1)-1',\n",
    "               is_quarterly=False, add_data=True)\n",
    "LossVariance60 = dv.add_formula('LossVariance60',\n",
    "                                '250*Ts_Sum(If(daily_return_no_reinv>0,0,daily_return_no_reinv*daily_return_no_reinv-daily_return_no_reinv),60)/Ts_Sum(If(daily_return_no_reinv>0,0,1),60)',\n",
    "                                is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS60 = dv.add_formula('BIAS60_J',\n",
    "                        '(close_adj/Ts_Sum(close_adj,60)*60-1)*100',\n",
    "                        is_quarterly=False, add_data=True)\n",
    "# BIAS60.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha110 = dv.add_formula('alpha110',\n",
    "                          'Ts_Sum(Max(0,high-Delay(close,1)),20)/Ts_Sum(Max(0,Delay(close,1)-low),20)*100',\n",
    "                          is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dv.add_formula('DMZ','If((high+low)>(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0)')\n",
    "# dv.add_formula('DMF','If((high+low)<(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0)')\n",
    "# dv.add_formula('diz','Ts_Sum(DMZ,13)/(Ts_Sum(DMZ,13)+Ts_Sum(DMF,13))')\n",
    "DIZ = dv.add_formula('DIZ_J',\n",
    "                     'Ts_Sum(If((high+low)>(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0),13)/(Ts_Sum(If((high+low)>(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0),13)+Ts_Sum(If((high+low)<(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0),13))'\n",
    "                     ,is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv.add_formula('a','close/Delay(close,1)-1',is_quarterly=False, add_data=True)\n",
    "dv.add_formula('b','(close/Delay(close,19))^(1/20)-1',is_quarterly=False, add_data=True)\n",
    "alpha190 = dv.add_formula('alpha190',\n",
    "                          'Log((Ts_Sum(If(a>b,1,0),20)-1)*Ts_Sum(If(a<b,(a-b)^2,0),20)/(Ts_Sum(If(a<b,1,0),20))*Ts_Sum(If(a>b,(a-b)^2,0),20))',\n",
    "                          is_quarterly=False, add_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤五：预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_zz500 = dp.daily_index_cons(api, \"000300.SH\", start, end)\n",
    "id_hs300 = dp.daily_index_cons(api, \"000905.SH\", start, end)\n",
    "\n",
    "columns_500 = list(set(id_zz500.columns)-set(id_hs300.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "id_member = pd.concat([id_zz500[columns_500],id_hs300],axis=1)\n",
    "mask = ~id_member\n",
    "import numpy as np\n",
    "\n",
    "# 定义可买卖条件——未停牌、未涨跌停\n",
    "def limit_up_down():\n",
    "    trade_status = dv.get_ts('trade_status').fillna(0)\n",
    "    mask_sus = trade_status == 0\n",
    "    # 涨停\n",
    "    up_limit = dv.add_formula('up_limit', '(close - Delay(close, 1)) / Delay(close, 1) > 0.095', is_quarterly=False)\n",
    "    # 跌停\n",
    "    down_limit = dv.add_formula('down_limit', '(close - Delay(close, 1)) / Delay(close, 1) < -0.095', is_quarterly=False)\n",
    "    can_enter = np.logical_and(up_limit < 1, ~mask_sus) # 未涨停未停牌\n",
    "    can_exit = np.logical_and(down_limit < 1, ~mask_sus) # 未跌停未停牌\n",
    "    return can_enter,can_exit\n",
    "can_enter,can_exit = limit_up_down()\n",
    "import numpy as np\n",
    "\n",
    "alpha_signal = ['TSEPToTotalCapital','alpha107','TRIX5_J','OperatingRevenueGrowRate_J','LossVariance60','BIAS60_J','alpha110','DIZ_J']\n",
    "\n",
    "price = dv.get_ts('close_adj')\n",
    "sw1 = sw1_name\n",
    "enter = can_enter\n",
    "exit =  can_exit\n",
    "mask = mask\n",
    "from jaqs_fxdayu.research.signaldigger.process import neutralize\n",
    "\n",
    "neutralize_dict = {a: neutralize(factor_df = dv.get_ts(a), group = dv.get_ts(\"sw1\")) for a in alpha_signal}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alpha_signal:\n",
    "    print(len((dv.get_ts(a)).columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  步骤六： 分析因子周期特点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from jaqs_fxdayu.research import SignalDigger\n",
    "from jaqs_fxdayu.research.signaldigger import analysis\n",
    "\n",
    "def cal_obj(signal, name, period, quantile):\n",
    "#     price_bench = dv.data_benchmark\n",
    "    obj = SignalDigger(output_folder=\"FACTORS/%s\" % name,\n",
    "                       output_format='pdf')\n",
    "    obj.process_signal_before_analysis(signal,\n",
    "                                   price=price,\n",
    "                                   n_quantiles=quantile, period=period,\n",
    "                                   mask=mask,\n",
    "                                   group=sw1,\n",
    "                                   can_enter = enter,\n",
    "                                   can_exit = exit,\n",
    "                                   commission = 0.0008\n",
    "                                   )\n",
    "    obj.create_full_report()\n",
    "    return obj\n",
    "\n",
    "def plot_pfm(signal, name, period=5, quantile=5):\n",
    "    obj = cal_obj(signal, name, period, quantile)\n",
    "    plt.show()\n",
    "def signal_data(signal, name, period=5, quantile=5):\n",
    "    obj = cal_obj(signal, name, period, quantile)\n",
    "    return obj.signal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_dict = {a:signal_data(neutralize_dict[a], a, 20) for a in alpha_signal} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_pn = pd.Panel({a: analysis.ic_stats(signals_dict[a]) for a in signals_dict.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_performance = round(ic_pn.minor_xs('return_ic'),2)\n",
    "print(alpha_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_IR = alpha_performance.loc[\"Ann. IR\"]\n",
    "alpha_IC = alpha_performance.loc[\"IC Mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_alpha = alpha_IC[(abs(alpha_IC)>=0.03) & (abs(alpha_IR)>=0.25) & alpha_IC*alpha_IR>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_alpha_dict = {g: float('%.2f' % good_alpha[g]) for g in good_alpha.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_alpha_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤七：查看因子行业特点（最优周期）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_dict = {alpha : signal_data(dv.get_ts(alpha), alpha, period=20, quantile=5) for alpha in good_alpha.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ic_length(signal, days=750):\n",
    "    return signal.loc[signal.index.levels[0][-days]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaqs.research.signaldigger import performance as pfm\n",
    "\n",
    "performance_dict = {}\n",
    "for alpha in good_alpha.index:\n",
    "    ic = pfm.calc_signal_ic(ic_length(signal_dict[alpha]), by_group=True)\n",
    "    mean_ic_by_group = pfm.mean_information_coefficient(ic, by_group=True)\n",
    "    performance_dict[alpha] = round(mean_ic_by_group,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_industry = pd.Panel(performance_dict).minor_xs('ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "High_IC_Industry = pd.DataFrame([ic_industry[abs(ic_industry)>=0.05][alpha].dropna(how='all') for alpha in good_alpha.index]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最终： 输出因子描述的Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(good_alpha_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Formula = {\n",
    "    'LossVariance60':'250*Ts_Sum(If(daily_return_no_reinv>0,0,daily_return_no_reinv*daily_return_no_reinv-daily_return_no_reinv),60)/Ts_Sum(If(daily_return_no_reinv>0,0,1),60)',\n",
    "    'TRIX5_J':'EMA3/Delay(EMA3,1)-1',\n",
    "    'BIAS60_J':'(close_adj/Ts_Sum(close_adj,60)*60-1)*100',\n",
    "    'DIZ_J':'Ts_Sum(If((high+low)>(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0),13)/(Ts_Sum(If((high+low)>(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0),13)+Ts_Sum(If((high+low)<(Delay(high,1)+Delay(low,1)),Max(Abs(high-Delay(high,1)),Abs(low-Delay(low,1))),0),13))'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaqs.data.py_expression_eval import Parser\n",
    "parser = Parser()\n",
    "factor={}\n",
    "for name in list(good_alpha_dict.keys()):\n",
    "    factor[name] = pd.Series({'name':name,\n",
    "                              'data':parser.parse(Formula[name]).variables(),\n",
    "                              'IC':good_alpha_dict[name],\n",
    "                              'type':'价量类',\n",
    "                              'market':'ZZ800',\n",
    "                              'classify':'sw1',\n",
    "                              'Formula':Formula[name],\n",
    "                              'parameter':[1,6],\n",
    "                              'description':'对数成交量的1天差与当天涨跌幅的过去6天相关系数',\n",
    "                              'High_IC_Industry': {indu: float('%.2f' % High_IC_Industry[name][indu]) for indu in High_IC_Industry[name].dropna().index}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(factor).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(factor).T.to_excel('Finish_factor.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# alpha_signal = ['TSEPToTotalCapital','alpha107','TRIX5_J','OperatingRevenueGrowRate_J','LossVariance60','BIAS60_J','alpha110','DIZ_J']\n",
    "#--------------------------------------------------------- \n",
    "#test output\n",
    "def test(factor,data):\n",
    "    if not isinstance(data, pd.core.frame.DataFrame):\n",
    "        raise TypeError('On factor {} ,output must be a pandas.DataFrame!'.format(factor))\n",
    "    else:\n",
    "        try:\n",
    "            index_name = data.index.names[0]\n",
    "            columns_name = data.index.names[0]\n",
    "        except:\n",
    "            if not (index_name in ['trade_date','report_date'] and columns_name == 'symbol'):\n",
    "                raise NameError('''Error index name,index name must in [\"trade_date\",\"report_date\"],columns name must be \"symbol\" ''')\n",
    "                \n",
    "        index_dtype = data.index.dtype_str\n",
    "        columns_dtype = data.columns.dtype_str\n",
    "        \n",
    "        if columns_dtype not in ['object','str']:\n",
    "            raise TypeError('error columns type')\n",
    "            \n",
    "        if index_dtype not in ['int32','int64','int']:\n",
    "            raise TypeError('error index type')\n",
    "        print ('{} OK!'.format(factor))\n",
    "        \n",
    "for f in alpha_signal:\n",
    "    test(f, dv.get_ts(f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
